{"cells":[{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from keras.datasets import cifar10\n","from keras.utils import to_categorical\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WSnQZDn8Rj0r","outputId":"74fd7f88-57a3-41bf-dee6-1081680b795c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 0us/step\n"]}]},{"cell_type":"code","source":["# from matplotlib import image\n","# from matplotlib import pyplot\n","# fig, axes = plt.subplots(10, 10, figsize=(15, 15))\n","# fig.subplots_adjust(hspace=0.5, wspace=0.5)\n","\n","# for class_idx in range(10):\n","#     # Find all indices for the current class\n","#     class_indices = np.where(y_train.flatten() == class_idx)[0]\n","#     # Pick 10 random samples from this class\n","#     random_indices = np.random.choice(class_indices, 10, replace=False)\n","\n","#     for i, img_idx in enumerate(random_indices):\n","#         ax = axes[class_idx, i]\n","#         ax.imshow(x_train[img_idx])\n","#         ax.axis('off')\n","\n","\n","# plt.show()\n","\n"],"metadata":{"id":"Tqlk7pB1R8Tn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def preprocess_data(x_train, y_train, x_test, y_test, num_classes=10):\n","    \"\"\"\n","    Preprocesses image and label data for training and testing.\n","\n","    This function normalizes image pixel values to the range [0, 1],\n","    flattens label arrays, and converts labels to one-hot encoded format.\n","\n","    Parameters\n","    ----------\n","    x_train : np.ndarray\n","        Training images, typically of shape (num_samples, height, width[, channels]).\n","    y_train : np.ndarray\n","        Training labels (integer-encoded).\n","    x_test : np.ndarray\n","        Test images, typically of shape (num_samples, height, width[, channels]).\n","    y_test : np.ndarray\n","        Test labels (integer-encoded).\n","    num_classes : int, optional\n","        Number of output classes for one-hot encoding. Default is 10.\n","\n","    Returns\n","    -------\n","    tuple\n","        A tuple containing:\n","        - x_train (np.ndarray): Normalized training images.\n","        - y_train_onehot (np.ndarray): One-hot encoded training labels.\n","        - x_test (np.ndarray): Normalized test images.\n","        - y_test_onehot (np.ndarray): One-hot encoded test labels.\n","    \"\"\"\n","    # Normalize image data\n","    x_train = x_train.astype(\"float32\") / 255.0\n","    x_test = x_test.astype(\"float32\") / 255.0\n","\n","    # Flatten label arrays\n","    y_train = y_train.flatten()\n","    y_test = y_test.flatten()\n","\n","    # One-hot encode labels\n","    y_train_onehot = to_categorical(y_train, num_classes=num_classes)\n","    y_test_onehot = to_categorical(y_test, num_classes=num_classes)\n","\n","    print(\"x_train shape:\", x_train.shape)\n","    print(\"y_train_onehot shape:\", y_train_onehot.shape)\n","\n","    return x_train, y_train_onehot, x_test, y_test_onehot\n","\n","x_train, y_train_onehot, x_test, y_test_onehot=preprocess_data(x_train, y_train, x_test, y_test, num_classes=10)\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ATiLiD_NSRCQ","outputId":"d0167bc2-1e85-445e-e066-3e70028e1d34"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["x_train shape: (50000, 32, 32, 3)\n","y_train_onehot shape: (50000, 10)\n"]}]},{"cell_type":"code","source":["# import tensorflow as tf\n","# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","# # One-hot encode labels\n","# y_train_onehot = to_categorical(y_train, num_classes=10)\n","# y_test_onehot = to_categorical(y_test, num_classes=10)\n","\n","# datagen = ImageDataGenerator(\n","#     rescale=1./255,             # Normalize\n","#     rotation_range=15,\n","#     width_shift_range=0.1,\n","#     height_shift_range=0.1,\n","#     horizontal_flip=True,\n","#     zoom_range=0.1,\n","# )\n","# train_generator = datagen.flow(\n","#     x_train, y_train_onehot,\n","#     batch_size=32\n","# )\n","\n","# test_datagen = ImageDataGenerator(rescale=1./255)\n","# test_generator = test_datagen.flow(x_test, y_test_onehot, batch_size=32)"],"metadata":{"id":"9gFTqhiBTwLg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.backend import clear_session\n","clear_session()\n","from keras import Sequential\n","from keras import layers\n","from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","\n","model = Sequential([\n","\n","    layers.Conv2D(32, (3,3), activation='relu', input_shape=(32, 32, 3)),\n","    layers.MaxPooling2D(pool_size=(2, 2)),\n","\n","    layers.Conv2D(64, (3,3), activation='relu'),\n","    layers.MaxPooling2D((2,2))\n","    ,\n","    layers.Conv2D(128, (3,3), activation='relu'),\n","\n","    layers.Flatten(),\n","    layers.Dense(128, activation='relu'),\n","    layers.Dropout(0.5),\n","\n","    layers.Dense(10, activation='softmax')\n","])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_VZ8HEwzT0dc","outputId":"26524224-6390-4e6c-f552-18a9d636c900"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]}]},{"cell_type":"code","source":["from keras.optimizers import SGD\n","from keras.optimizers import Adam\n","optimizer =Adam(learning_rate=0.001)\n","model.compile(\n","    optimizer=optimizer,\n","    loss='categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n","history = model.fit(\n","    x_train, y_train_onehot,\n","    epochs=50,\n","    batch_size=512,\n","    validation_split=0.2\n",")\n","\n","test_loss, test_accuracy = model.evaluate(x_test, y_test_onehot, verbose=1)\n","\n","print(f\"Test Loss: {test_loss:.4f}\")\n","print(f\"Test Accuracy: {test_accuracy:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_2jCjb0NT6hl","outputId":"1a66b9eb-1ac3-4e7e-8766-1020a996bc0d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.2045 - loss: 2.1217 - val_accuracy: 0.3910 - val_loss: 1.6576\n","Epoch 2/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.3859 - loss: 1.6714 - val_accuracy: 0.4803 - val_loss: 1.4594\n","Epoch 3/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.4498 - loss: 1.5077 - val_accuracy: 0.5114 - val_loss: 1.3715\n","Epoch 4/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.4903 - loss: 1.4182 - val_accuracy: 0.5349 - val_loss: 1.3005\n","Epoch 5/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5107 - loss: 1.3548 - val_accuracy: 0.5432 - val_loss: 1.2899\n","Epoch 6/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5365 - loss: 1.3040 - val_accuracy: 0.5559 - val_loss: 1.2454\n","Epoch 7/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5481 - loss: 1.2589 - val_accuracy: 0.5845 - val_loss: 1.1710\n","Epoch 8/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5748 - loss: 1.1974 - val_accuracy: 0.6061 - val_loss: 1.1181\n","Epoch 9/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5932 - loss: 1.1536 - val_accuracy: 0.6150 - val_loss: 1.1014\n","Epoch 10/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6003 - loss: 1.1359 - val_accuracy: 0.6136 - val_loss: 1.1037\n","Epoch 11/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6092 - loss: 1.1048 - val_accuracy: 0.6230 - val_loss: 1.0736\n","Epoch 12/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6279 - loss: 1.0660 - val_accuracy: 0.6495 - val_loss: 1.0018\n","Epoch 13/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6417 - loss: 1.0261 - val_accuracy: 0.6609 - val_loss: 0.9803\n","Epoch 14/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6443 - loss: 1.0153 - val_accuracy: 0.6592 - val_loss: 0.9645\n","Epoch 15/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6610 - loss: 0.9611 - val_accuracy: 0.6490 - val_loss: 0.9852\n","Epoch 16/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6591 - loss: 0.9691 - val_accuracy: 0.6811 - val_loss: 0.9190\n","Epoch 17/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6835 - loss: 0.9101 - val_accuracy: 0.6557 - val_loss: 0.9814\n","Epoch 18/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6740 - loss: 0.9303 - val_accuracy: 0.6894 - val_loss: 0.8914\n","Epoch 19/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6903 - loss: 0.8902 - val_accuracy: 0.6812 - val_loss: 0.9183\n","Epoch 20/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7009 - loss: 0.8568 - val_accuracy: 0.7029 - val_loss: 0.8622\n","Epoch 21/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7050 - loss: 0.8480 - val_accuracy: 0.6964 - val_loss: 0.8830\n","Epoch 22/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7132 - loss: 0.8236 - val_accuracy: 0.7048 - val_loss: 0.8567\n","Epoch 23/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7217 - loss: 0.7952 - val_accuracy: 0.6972 - val_loss: 0.8950\n","Epoch 24/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7278 - loss: 0.7836 - val_accuracy: 0.6956 - val_loss: 0.8891\n","Epoch 25/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7267 - loss: 0.7755 - val_accuracy: 0.7053 - val_loss: 0.8747\n","Epoch 26/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7316 - loss: 0.7516 - val_accuracy: 0.7176 - val_loss: 0.8263\n","Epoch 27/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7379 - loss: 0.7464 - val_accuracy: 0.7077 - val_loss: 0.8535\n","Epoch 28/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7507 - loss: 0.7093 - val_accuracy: 0.7201 - val_loss: 0.8287\n","Epoch 29/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7530 - loss: 0.6981 - val_accuracy: 0.7209 - val_loss: 0.8201\n","Epoch 30/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7537 - loss: 0.6964 - val_accuracy: 0.7081 - val_loss: 0.8758\n","Epoch 31/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7625 - loss: 0.6680 - val_accuracy: 0.7226 - val_loss: 0.8195\n","Epoch 32/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7650 - loss: 0.6618 - val_accuracy: 0.7239 - val_loss: 0.8223\n","Epoch 33/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7730 - loss: 0.6422 - val_accuracy: 0.7302 - val_loss: 0.8010\n","Epoch 34/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7794 - loss: 0.6166 - val_accuracy: 0.7255 - val_loss: 0.8236\n","Epoch 35/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7824 - loss: 0.6158 - val_accuracy: 0.7324 - val_loss: 0.8213\n","Epoch 36/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7847 - loss: 0.6055 - val_accuracy: 0.7275 - val_loss: 0.8239\n","Epoch 37/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7903 - loss: 0.5894 - val_accuracy: 0.7171 - val_loss: 0.8671\n","Epoch 38/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7924 - loss: 0.5966 - val_accuracy: 0.7175 - val_loss: 0.8979\n","Epoch 39/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7969 - loss: 0.5690 - val_accuracy: 0.7316 - val_loss: 0.8473\n","Epoch 40/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8030 - loss: 0.5514 - val_accuracy: 0.7228 - val_loss: 0.8664\n","Epoch 41/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8036 - loss: 0.5491 - val_accuracy: 0.7256 - val_loss: 0.8555\n","Epoch 42/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8125 - loss: 0.5301 - val_accuracy: 0.7252 - val_loss: 0.8487\n","Epoch 43/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8192 - loss: 0.5062 - val_accuracy: 0.7321 - val_loss: 0.8471\n","Epoch 44/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8186 - loss: 0.5087 - val_accuracy: 0.7251 - val_loss: 0.8831\n","Epoch 45/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8223 - loss: 0.4986 - val_accuracy: 0.7166 - val_loss: 0.9098\n","Epoch 46/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8214 - loss: 0.4917 - val_accuracy: 0.7239 - val_loss: 0.8879\n","Epoch 47/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8223 - loss: 0.4949 - val_accuracy: 0.7328 - val_loss: 0.8808\n","Epoch 48/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8344 - loss: 0.4608 - val_accuracy: 0.7231 - val_loss: 0.9338\n","Epoch 49/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8350 - loss: 0.4550 - val_accuracy: 0.7271 - val_loss: 0.9005\n","Epoch 50/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8332 - loss: 0.4601 - val_accuracy: 0.7304 - val_loss: 0.8991\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7297 - loss: 0.8684\n","Test Loss: 0.8954\n","Test Accuracy: 0.7236\n"]}]},{"cell_type":"code","source":["\n","model2 = Sequential([\n","    layers.Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3)),\n","    layers.BatchNormalization(),\n","\n","    layers.Conv2D(64, (3,3), activation='relu'),\n","    layers.BatchNormalization(),\n","    layers.MaxPooling2D((2,2)),\n","\n","    layers.Conv2D(128, (3,3), activation='relu'),\n","    layers.BatchNormalization(),\n","    layers.MaxPooling2D((2,2)),\n","\n","    layers.Flatten(),\n","    layers.Dense(256, activation='relu'),\n","    layers.Dropout(0.5),   # Prevents overfitting\n","    layers.Dense(10, activation='softmax')\n","])\n","optimizer =Adam(learning_rate=0.002)\n","model2.compile(\n","    optimizer=optimizer,\n","    loss='categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n","history2 = model2.fit(\n","    x_train, y_train_onehot,\n","    epochs=20,\n","    batch_size=128,\n","    validation_split=0.2\n",")\n","\n","test_loss2, test_accuracy2 = model2.evaluate(x_test, y_test_onehot, verbose=1)\n","\n","print(f\"Test Loss: {test_loss2:.4f}\")\n","print(f\"Test Accuracy: {test_accuracy2:.4f}\")"],"metadata":{"id":"DaLzDTBN9CjX","outputId":"e647d9cd-abd9-4aff-8946-1a060d474a3f","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 28ms/step - accuracy: 0.3299 - loss: 2.1824 - val_accuracy: 0.1800 - val_loss: 3.0904\n","Epoch 2/20\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.5284 - loss: 1.3306 - val_accuracy: 0.6215 - val_loss: 1.1041\n","Epoch 3/20\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.6122 - loss: 1.1083 - val_accuracy: 0.6087 - val_loss: 1.1036\n","Epoch 4/20\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.6639 - loss: 0.9572 - val_accuracy: 0.6533 - val_loss: 1.0007\n","Epoch 5/20\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.6998 - loss: 0.8572 - val_accuracy: 0.6764 - val_loss: 0.9352\n","Epoch 6/20\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.7346 - loss: 0.7693 - val_accuracy: 0.7144 - val_loss: 0.8724\n","Epoch 7/20\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.7539 - loss: 0.7120 - val_accuracy: 0.7033 - val_loss: 0.9347\n","Epoch 8/20\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.7769 - loss: 0.6390 - val_accuracy: 0.6925 - val_loss: 1.1365\n","Epoch 9/20\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.7957 - loss: 0.5709 - val_accuracy: 0.7357 - val_loss: 0.8029\n","Epoch 10/20\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.8171 - loss: 0.5270 - val_accuracy: 0.7465 - val_loss: 0.8579\n","Epoch 11/20\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.8249 - loss: 0.4993 - val_accuracy: 0.7190 - val_loss: 0.9444\n","Epoch 12/20\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.8374 - loss: 0.4597 - val_accuracy: 0.7430 - val_loss: 0.8196\n","Epoch 13/20\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.8544 - loss: 0.4103 - val_accuracy: 0.7539 - val_loss: 0.8876\n","Epoch 14/20\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.8603 - loss: 0.3913 - val_accuracy: 0.7512 - val_loss: 0.8244\n","Epoch 15/20\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.8694 - loss: 0.3694 - val_accuracy: 0.7498 - val_loss: 0.9369\n","Epoch 16/20\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.8785 - loss: 0.3476 - val_accuracy: 0.7606 - val_loss: 0.8598\n","Epoch 17/20\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.8867 - loss: 0.3201 - val_accuracy: 0.7574 - val_loss: 0.8744\n","Epoch 18/20\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.8938 - loss: 0.2971 - val_accuracy: 0.7658 - val_loss: 0.9235\n","Epoch 19/20\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.8964 - loss: 0.2900 - val_accuracy: 0.7421 - val_loss: 1.0298\n","Epoch 20/20\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9039 - loss: 0.2669 - val_accuracy: 0.7639 - val_loss: 0.9513\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7643 - loss: 0.9573\n","Test Loss: 0.9573\n","Test Accuracy: 0.7631\n"]}]},{"cell_type":"code","source":["model3 = Sequential([\n","    layers.Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3)),\n","    layers.BatchNormalization(),\n","\n","    layers.Conv2D(64, (3,3), activation='relu'),\n","    layers.BatchNormalization(),\n","    layers.MaxPooling2D((2,2)),\n","\n","    layers.Conv2D(128, (3,3), activation='relu'),\n","    layers.BatchNormalization(),\n","    layers.MaxPooling2D((2,2)),\n","\n","    layers.Conv2D(128, (3,3), activation='relu'),\n","    layers.BatchNormalization(),\n","    layers.MaxPooling2D((2,2)),\n","\n","    layers.Flatten(),\n","    layers.Dense(256, activation='relu'),\n","    layers.Dropout(0.5),   # Prevents overfitting\n","    layers.Dense(10, activation='softmax')\n","])\n","optimizer =Adam(learning_rate=0.002)\n","model3.compile(\n","    optimizer=optimizer,\n","    loss='categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n","history3 = model3.fit(\n","    x_train, y_train_onehot,\n","    epochs=50,\n","    batch_size=256,\n","    validation_split=0.2\n",")\n","\n"],"metadata":{"id":"fiShzDoIKlZX","outputId":"a30b07dd-7b0f-4f80-f36f-3b3ea412bd86","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 51ms/step - accuracy: 0.3562 - loss: 1.9800 - val_accuracy: 0.1031 - val_loss: 3.2894\n","Epoch 2/50\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.5911 - loss: 1.1455 - val_accuracy: 0.2053 - val_loss: 2.9596\n","Epoch 3/50\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.6875 - loss: 0.8955 - val_accuracy: 0.4116 - val_loss: 1.9515\n","Epoch 4/50\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.7348 - loss: 0.7535 - val_accuracy: 0.6737 - val_loss: 0.9575\n","Epoch 5/50\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.7680 - loss: 0.6557 - val_accuracy: 0.7271 - val_loss: 0.7785\n","Epoch 6/50\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.7935 - loss: 0.5764 - val_accuracy: 0.7469 - val_loss: 0.7600\n","Epoch 7/50\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.8221 - loss: 0.5048 - val_accuracy: 0.7437 - val_loss: 0.7764\n","Epoch 8/50\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.8489 - loss: 0.4314 - val_accuracy: 0.7674 - val_loss: 0.7442\n","Epoch 9/50\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.8659 - loss: 0.3717 - val_accuracy: 0.7454 - val_loss: 0.8228\n","Epoch 10/50\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.8826 - loss: 0.3255 - val_accuracy: 0.7335 - val_loss: 0.9070\n","Epoch 11/50\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.8907 - loss: 0.3082 - val_accuracy: 0.7632 - val_loss: 0.8505\n","Epoch 12/50\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.9089 - loss: 0.2575 - val_accuracy: 0.7452 - val_loss: 0.9584\n","Epoch 13/50\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.9224 - loss: 0.2221 - val_accuracy: 0.7560 - val_loss: 0.9625\n","Epoch 14/50\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.9244 - loss: 0.2075 - val_accuracy: 0.7411 - val_loss: 1.0133\n","Epoch 15/50\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.9341 - loss: 0.1872 - val_accuracy: 0.7729 - val_loss: 0.9360\n","Epoch 16/50\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.9389 - loss: 0.1728 - val_accuracy: 0.7713 - val_loss: 1.0292\n","Epoch 17/50\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.9516 - loss: 0.1436 - val_accuracy: 0.7481 - val_loss: 1.2178\n","Epoch 18/50\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.9533 - loss: 0.1379 - val_accuracy: 0.7767 - val_loss: 1.0609\n","Epoch 19/50\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.9575 - loss: 0.1241 - val_accuracy: 0.7739 - val_loss: 1.0269\n","Epoch 20/50\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.9557 - loss: 0.1284 - val_accuracy: 0.7442 - val_loss: 1.3330\n","Epoch 21/50\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.9554 - loss: 0.1331 - val_accuracy: 0.7631 - val_loss: 1.1602\n","Epoch 22/50\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.9625 - loss: 0.1102 - val_accuracy: 0.7623 - val_loss: 1.2387\n","Epoch 23/50\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.9619 - loss: 0.1161 - val_accuracy: 0.7733 - val_loss: 1.1778\n","Epoch 24/50\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.9651 - loss: 0.1023 - val_accuracy: 0.7680 - val_loss: 1.2030\n","Epoch 25/50\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.9656 - loss: 0.1022 - val_accuracy: 0.7750 - val_loss: 1.2690\n","Epoch 26/50\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.9696 - loss: 0.0898 - val_accuracy: 0.7671 - val_loss: 1.3435\n","Epoch 27/50\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.9666 - loss: 0.1006 - val_accuracy: 0.7792 - val_loss: 1.3633\n","Epoch 28/50\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.9759 - loss: 0.0715 - val_accuracy: 0.7558 - val_loss: 1.5666\n","Epoch 29/50\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.9776 - loss: 0.0664 - val_accuracy: 0.7752 - val_loss: 1.5212\n","Epoch 30/50\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.9699 - loss: 0.0895 - val_accuracy: 0.7725 - val_loss: 1.4105\n","Epoch 31/50\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.9740 - loss: 0.0743 - val_accuracy: 0.7510 - val_loss: 1.4750\n","Epoch 32/50\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.9777 - loss: 0.0623 - val_accuracy: 0.7767 - val_loss: 1.4007\n","Epoch 33/50\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.9788 - loss: 0.0642 - val_accuracy: 0.7717 - val_loss: 1.4209\n","Epoch 34/50\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.9762 - loss: 0.0711 - val_accuracy: 0.7629 - val_loss: 1.4993\n","Epoch 35/50\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.9743 - loss: 0.0780 - val_accuracy: 0.7748 - val_loss: 1.3991\n","Epoch 36/50\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.9784 - loss: 0.0658 - val_accuracy: 0.7790 - val_loss: 1.4366\n","Epoch 37/50\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.9813 - loss: 0.0587 - val_accuracy: 0.7654 - val_loss: 1.5741\n","Epoch 38/50\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.9797 - loss: 0.0622 - val_accuracy: 0.7708 - val_loss: 1.5154\n","Epoch 39/50\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.9780 - loss: 0.0631 - val_accuracy: 0.7721 - val_loss: 1.6074\n","Epoch 40/50\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.9805 - loss: 0.0566 - val_accuracy: 0.7820 - val_loss: 1.4989\n","Epoch 41/50\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.9817 - loss: 0.0555 - val_accuracy: 0.7555 - val_loss: 1.6044\n","Epoch 42/50\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.9769 - loss: 0.0684 - val_accuracy: 0.7613 - val_loss: 1.6125\n","Epoch 43/50\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.9820 - loss: 0.0573 - val_accuracy: 0.7694 - val_loss: 1.5672\n","Epoch 44/50\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.9805 - loss: 0.0578 - val_accuracy: 0.7690 - val_loss: 1.3746\n","Epoch 45/50\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.9814 - loss: 0.0582 - val_accuracy: 0.7774 - val_loss: 1.5622\n","Epoch 46/50\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.9829 - loss: 0.0545 - val_accuracy: 0.7751 - val_loss: 1.4913\n","Epoch 47/50\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.9861 - loss: 0.0450 - val_accuracy: 0.7815 - val_loss: 1.6443\n","Epoch 48/50\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.9836 - loss: 0.0493 - val_accuracy: 0.7622 - val_loss: 1.5798\n","Epoch 49/50\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.9829 - loss: 0.0556 - val_accuracy: 0.7737 - val_loss: 1.4663\n","Epoch 50/50\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.9837 - loss: 0.0512 - val_accuracy: 0.7688 - val_loss: 1.6011\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7643 - loss: 0.9573\n","Test Loss: 0.9573\n","Test Accuracy: 0.7631\n"]}]},{"cell_type":"code","source":["test_loss3, test_accuracy3 = model3.evaluate(x_test, y_test_onehot, verbose=1)\n","print(f\"Test Loss: {test_loss3:.4f}\")\n","print(f\"Test Accuracy: {test_accuracy3:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":176},"id":"4vmbnKtSWXsc","outputId":"8271b5a7-f495-4457-e195-9d6bcd5d3381","executionInfo":{"status":"error","timestamp":1761204404189,"user_tz":-120,"elapsed":57,"user":{"displayName":"khushboo shrivastava","userId":"13813422655626291699"}}},"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'model3' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-4239524238.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_loss3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_onehot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Test Loss: {test_loss3:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Test Accuracy: {test_accuracy3:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model3' is not defined"]}]},{"cell_type":"code","source":["from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n","\n","early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n","reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n","\n","model4 = Sequential([\n","    layers.Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3)),\n","    layers.BatchNormalization(),\n","\n","    layers.Conv2D(64, (3,3), activation='relu'),\n","    layers.BatchNormalization(),\n","    layers.MaxPooling2D((2,2)),\n","\n","    layers.Conv2D(128, (3,3), activation='relu'),\n","    layers.BatchNormalization(),\n","    layers.MaxPooling2D((2,2)),\n","\n","    layers.Conv2D(128, (3,3), activation='relu'),\n","    layers.BatchNormalization(),\n","    layers.MaxPooling2D((2,2)),\n","\n","\n","\n","    layers.Flatten(),\n","    layers.Dense(256, activation='relu'),\n","    layers.Dropout(0.5),   # Prevents overfitting\n","    layers.Dense(10, activation='softmax')\n","])\n","optimizer =Adam(learning_rate=0.002)\n","model4.compile(\n","    optimizer=optimizer,\n","    loss='categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n","\n","history4 = model4.fit(\n","    x_train, y_train_onehot,\n","    epochs=50,\n","    batch_size=512,\n","    validation_split=0.2,\n","    callbacks=[early_stop, reduce_lr]\n",")\n","test_loss4, test_accuracy4 = model4.evaluate(x_test, y_test_onehot, verbose=1)\n","print(f\"Test Loss: {test_loss4:.4f}\")\n","print(f\"Test Accuracy: {test_accuracy4:.4f}\")"],"metadata":{"id":"ZcFdB5XSb2dJ","outputId":"227a7318-0702-42f1-8e95-ea638bdf3c99","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 101ms/step - accuracy: 0.3380 - loss: 2.0935 - val_accuracy: 0.1175 - val_loss: 3.6032 - learning_rate: 0.0020\n","Epoch 2/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.5599 - loss: 1.2303 - val_accuracy: 0.1906 - val_loss: 3.3742 - learning_rate: 0.0020\n","Epoch 3/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.6483 - loss: 0.9836 - val_accuracy: 0.1794 - val_loss: 3.4451 - learning_rate: 0.0020\n","Epoch 4/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.7069 - loss: 0.8308 - val_accuracy: 0.1684 - val_loss: 4.1514 - learning_rate: 0.0020\n","Epoch 5/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.7446 - loss: 0.7244 - val_accuracy: 0.2923 - val_loss: 2.8652 - learning_rate: 0.0020\n","Epoch 6/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.7860 - loss: 0.6130 - val_accuracy: 0.4203 - val_loss: 1.9328 - learning_rate: 0.0020\n","Epoch 7/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.8065 - loss: 0.5488 - val_accuracy: 0.6114 - val_loss: 1.2422 - learning_rate: 0.0020\n","Epoch 8/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.8207 - loss: 0.5089 - val_accuracy: 0.7317 - val_loss: 0.8333 - learning_rate: 0.0020\n","Epoch 9/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.8469 - loss: 0.4347 - val_accuracy: 0.7400 - val_loss: 0.7824 - learning_rate: 0.0020\n","Epoch 10/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.8713 - loss: 0.3684 - val_accuracy: 0.7543 - val_loss: 0.8272 - learning_rate: 0.0020\n","Epoch 11/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.8854 - loss: 0.3198 - val_accuracy: 0.7632 - val_loss: 0.8247 - learning_rate: 0.0020\n","Epoch 12/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.8832 - loss: 0.3295 - val_accuracy: 0.7573 - val_loss: 0.8497 - learning_rate: 0.0020\n","Epoch 13/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.9307 - loss: 0.1961 - val_accuracy: 0.7866 - val_loss: 0.8065 - learning_rate: 0.0010\n","Epoch 14/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.9532 - loss: 0.1335 - val_accuracy: 0.7867 - val_loss: 0.9149 - learning_rate: 0.0010\n","Epoch 15/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.9642 - loss: 0.1072 - val_accuracy: 0.7813 - val_loss: 0.9559 - learning_rate: 0.0010\n","Epoch 16/50\n","\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.9771 - loss: 0.0709 - val_accuracy: 0.7946 - val_loss: 0.9164 - learning_rate: 5.0000e-04\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7421 - loss: 0.7839\n","Test Loss: 0.7893\n","Test Accuracy: 0.7388\n"]}]}],"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4"},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}